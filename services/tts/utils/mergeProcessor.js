// =======================================================================
// üéß MODULAR STREAMING MERGE PROCESSOR
// Supports mixing remote URLs + local batch files safely
// =======================================================================

import fs from "fs";
import path from "path";
import { spawn } from "child_process";
import fetch from "node-fetch";
import { info, error, warn , debug} from "../../../logger.js";
import { startKeepAlive, stopKeepAlive } from "../../shared/utils/keepalive.js";
import { uploadBuffer } from "../../shared/utils/r2-client.js";

const TMP_DIR = "/tmp/podcast_merge";
const MERGED_BUCKET = "merged";

// ------------------------------------------------------------
// ‚öôÔ∏è Environment-based tuning
// ------------------------------------------------------------
const DOWNLOAD_TIMEOUT_MS = Number(process.env.AI_TIMEOUT || 30000);
const MAX_RETRIES = Number(process.env.MAX_CHUNK_RETRIES || 3);
const DOWNLOAD_RETRIES = MAX_RETRIES;
const MERGE_RETRIES = MAX_RETRIES;
const RETRY_DELAY_MS = Number(process.env.RETRY_DELAY_MS || 2000);
const RETRY_BACKOFF_MULTIPLIER =
  Number(process.env.RETRY_BACKOFF_MULTIPLIER || 2);

// Merge smaller groups recursively
const BATCH_SIZE = 2;

// ------------------------------------------------------------
// üõ° Create merge directory
// ------------------------------------------------------------
function ensureTmpDir() {
  if (!fs.existsSync(TMP_DIR)) fs.mkdirSync(TMP_DIR, { recursive: true });
}

// ------------------------------------------------------------
// üß† Type Guard ‚Äî remote URL or local file?
// ------------------------------------------------------------
function isRemote(input) {
  return typeof input === "string" && /^https?:\/\//i.test(input);
}

// ------------------------------------------------------------
// üåê Remote Download w/ Timeout + Retries
// ------------------------------------------------------------
async function fetchWithTimeout(url) {
  return Promise.race([
    fetch(url),
    new Promise((_, reject) =>
      setTimeout(
        () => reject(new Error(`Download timeout`)),
        DOWNLOAD_TIMEOUT_MS
      )
    ),
  ]);
}

async function downloadRemoteToBuffer(url, attempt = 1) {
  try {
    const res = await fetchWithTimeout(url);
    if (!res.ok) throw new Error(`HTTP ${res.status}`);
    return Buffer.from(await res.arrayBuffer());
  } catch (err) {
    if (attempt < DOWNLOAD_RETRIES) {
      const delay =
        RETRY_DELAY_MS * Math.pow(RETRY_BACKOFF_MULTIPLIER, attempt - 1);

      warn("Retrying remote download", { attempt, delayMs: delay });
      await new Promise((resolve) => setTimeout(resolve, delay));
      return downloadRemoteToBuffer(url, attempt + 1);
    }
    throw new Error(`Remote download failed after ${DOWNLOAD_RETRIES} attempts`);
  }
}

// ------------------------------------------------------------
// üìÅ Local File Read w/ Retry
// ------------------------------------------------------------
async function loadLocalToBuffer(localPath, attempt = 1) {
  try {
    return fs.readFileSync(localPath);
  } catch (err) {
    if (attempt < DOWNLOAD_RETRIES) {
      const delay =
        RETRY_DELAY_MS * Math.pow(RETRY_BACKOFF_MULTIPLIER, attempt - 1);

      warn("Retrying local file read", { attempt, delayMs: delay });
      await new Promise((resolve) => setTimeout(resolve, delay));
      return loadLocalToBuffer(localPath, attempt + 1);
    }
    throw new Error(`Local file read failed after ${DOWNLOAD_RETRIES} attempts`);
  }
}

// ------------------------------------------------------------
// ü§ù Unified Buffer Loader (Remote or Local)
// ------------------------------------------------------------
async function loadChunk(input) {
  if (isRemote(input)) return downloadRemoteToBuffer(input);
  return loadLocalToBuffer(input);
}

// ------------------------------------------------------------
// üéß STREAM MERGE ‚Äî merge array of buffers into outputPath
// ------------------------------------------------------------
async function streamMergeBuffers(buffers, outputPath, attempt = 1) {
  try {
    const ff = spawn("ffmpeg", [
      "-hide_banner",
      "-loglevel",
      "error",
      "-f",
      "mp3",
      "-i",
      "pipe:0",
      "-c",
      "copy",
      "-y",
      outputPath,
    ]);

    let stderr = "";

    ff.stderr.on("data", (d) => (stderr += d.toString()));

    await new Promise((resolve, reject) => {
      for (const buf of buffers) {
        const ok = ff.stdin.write(buf);
        if (!ok) ff.stdin.once("drain", () => {});
      }
      ff.stdin.end();

      ff.on("close", (code) => {
        if (code !== 0) {
          return reject(
            new Error(`FFmpeg failed (code ${code}): ${stderr}`)
          );
        }
        resolve();
      });
    });

    return outputPath;
  } catch (err) {
    if (attempt < MERGE_RETRIES) {
      const delay =
        RETRY_DELAY_MS * Math.pow(RETRY_BACKOFF_MULTIPLIER, attempt - 1);

      warn("Retrying merge batch", { attempt, delayMs: delay });
      return streamMergeBuffers(buffers, outputPath, attempt + 1);
    }
    throw err;
  }
}

// ------------------------------------------------------------
// üß© MODULAR BATCH MERGE (recursive, bulletproof)
// ------------------------------------------------------------
async function modularMerge(sessionId, sources) {
  let round = 1;
  let current = sources;

  while (current.length > 1) {
    debug ("Batch merge round", {
      round,
      chunksRemaining: current.length,
    });

    const next = [];

    for (let i = 0; i < current.length; i += BATCH_SIZE) {
      const group = current.slice(i, i + BATCH_SIZE);

      const buffers = [];
      for (const source of group) {
        buffers.push(await loadChunk(source));
      }

      const batchOutput = path.join(
        TMP_DIR,
        `${sessionId}_batch_${round}_${i}.mp3`
      );

      await streamMergeBuffers(buffers, batchOutput);
      next.push(batchOutput);
    }

    current = next;
    round++;
  }

  return current[0];
}

// ------------------------------------------------------------
// üßπ MEMORY CLEANUP - Remove temporary files
// ------------------------------------------------------------
function scheduleCleanup(finalPath, sessionId, delayMs = 120000) {
  setTimeout(() => {
    try {
      // Clean up the final merged file
      if (fs.existsSync(finalPath)) {
        fs.unlinkSync(finalPath);
        debug("üßπ Cleaned up final merged file", { path: finalPath });
      }

      // Clean up any intermediate batch files
      const files = fs.readdirSync(TMP_DIR);
      const sessionFiles = files.filter(file => file.startsWith(sessionId));
      
      sessionFiles.forEach(file => {
        const filePath = path.join(TMP_DIR, file);
        try {
          fs.unlinkSync(filePath);
          debug("üßπ Cleaned up intermediate file", { file });
        } catch (err) {
          warn("Failed to clean up intermediate file", { file, error: err.message });
        }
      });

      info("üßπ Memory cleanup completed", { 
        sessionId, 
        filesRemoved: sessionFiles.length + (fs.existsSync(finalPath) ? 1 : 0)
      });
    } catch (err) {
      error("Memory cleanup failed", { 
        sessionId, 
        error: err.message 
      });
    }
  }, delayMs);
}

// ------------------------------------------------------------
// üöÄ MAIN PROCESSOR
// ------------------------------------------------------------
export async function mergeProcessor(sessionId, chunkUrls = []) {
  const sid = sessionId || `TT-${Date.now()}`;
  const label = `mergeProcessor:${sid}`;

  startKeepAlive(label, 25000);
  ensureTmpDir();
  info("üéûÔ∏è Starting merge process")
  debug("Starting merge process", {
    sessionId: sid,
    totalChunks: chunkUrls.length,
  });

  try {
    if (!Array.isArray(chunkUrls) || chunkUrls.length === 0) {
      throw new Error("mergeProcessor requires chunk URLs.");
    }

    const finalPath = await modularMerge(sid, chunkUrls);

    const mergedBuf = fs.readFileSync(finalPath);
    const mergedKey = `${sid}.mp3`;

    await uploadBuffer(MERGED_BUCKET, mergedKey, mergedBuf, "audio/mpeg");

    // ‚úÖ CLEAN COMPLETION SUMMARY
    info("üü© Merge process completed")
    debug("üü© Merge process completed", {
      sessionId: sid,
      chunksProcessed: chunkUrls.length,
      outputKey: mergedKey,
      status: "success"
    });

    // üßπ SCHEDULE MEMORY CLEANUP WITH SILENT DELAY
    scheduleCleanup(finalPath, sid, 120000); // 2 minutes delay
    info("üßπ Memory cleanup scheduled", { 
      sessionId: sid, 
      cleanupIn: "2 minutes" 
    });

    stopKeepAlive(label);
    return { key: mergedKey, localPath: finalPath };
  } catch (err) {
    error("Merge process failed", { 
      sessionId: sid,
      error: err.message,
      status: "failed"
    });
    stopKeepAlive(label);
    throw err;
  }
}

export default mergeProcessor;
